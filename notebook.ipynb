{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aafb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'path/to/your/private/dataset'  \n",
    "CLASSES = ['lenggang', 'joged', 'hitammanis', 'kembangpayung', 'langkahjepen']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "FRAME_SIZE = 224\n",
    "NUM_FRAMES = 30\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "MODEL_PATH = './final6_i3d_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "I3D_MODEL_URL = \"https://tfhub.dev/deepmind/i3d-kinetics-400/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4db596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video_frames(video_path, num_frames=NUM_FRAMES, frame_size=FRAME_SIZE):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    frame_step = max(total_frames // num_frames, 1)\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while len(frames) < num_frames and cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_step == 0:\n",
    "            frame = cv2.resize(frame, (frame_size, frame_size))\n",
    "            frame = frame / 255.0\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == num_frames:\n",
    "                break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(np.zeros((frame_size, frame_size, 3)))  \n",
    "\n",
    "    return np.array(frames, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32722fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for class_idx, class_name in enumerate(CLASSES):\n",
    "        for i in range(1, 201):  \n",
    "            video_name = f\"{class_name}_{i}.mp4\"\n",
    "            video_path = os.path.join(DATA_PATH, video_name)\n",
    "            \n",
    "            if os.path.exists(video_path):\n",
    "                video_paths.append(video_path)\n",
    "                labels.append(class_idx)\n",
    "            else:\n",
    "                print(f\"Warning: Missing file {video_path}\")\n",
    "\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        video_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    return (train_paths, train_labels), (val_paths, val_labels)\n",
    "\n",
    "(train_paths, train_labels), (val_paths, val_labels) = create_dataset()\n",
    "print(f\"Training samples: {len(train_paths)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7290ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, video_paths, labels, batch_size=BATCH_SIZE, num_frames=NUM_FRAMES, shuffle=True):\n",
    "        self.video_paths = video_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_frames = num_frames\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.video_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.video_paths[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_labels = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        batch_frames = []\n",
    "        for path in batch_paths:\n",
    "            frames = load_video_frames(path, self.num_frames)\n",
    "            batch_frames.append(frames)\n",
    "\n",
    "        return np.array(batch_frames), tf.keras.utils.to_categorical(batch_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            indices = np.arange(len(self.video_paths))\n",
    "            np.random.shuffle(indices)\n",
    "            self.video_paths = [self.video_paths[i] for i in indices]\n",
    "            self.labels = [self.labels[i] for i in indices]\n",
    "\n",
    "train_generator = VideoDataGenerator(train_paths, train_labels)\n",
    "val_generator = VideoDataGenerator(val_paths, val_labels, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class I3DWrapper(tf.keras.layers.Layer):\n",
    "    def __init__(self, hub_url, **kwargs):\n",
    "        super(I3DWrapper, self).__init__(**kwargs)\n",
    "        self.hub_url = hub_url\n",
    "        self.i3d = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Load the I3D model\n",
    "        self.i3d = hub.load(self.hub_url).signatures['default']\n",
    "        # Initialize with a dummy input\n",
    "        dummy_input = tf.zeros((1, NUM_FRAMES, FRAME_SIZE, FRAME_SIZE, 3))\n",
    "        _ = self.i3d(dummy_input)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        outputs = self.i3d(inputs)\n",
    "        # Return the features (will be 400 for kinetics-400 model)\n",
    "        return outputs['default']\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = tf.keras.Input(shape=(NUM_FRAMES, FRAME_SIZE, FRAME_SIZE, 3))\n",
    "\n",
    "    # Use our wrapper layer - outputs (None, 400)\n",
    "    x = I3DWrapper(I3D_MODEL_URL)(inputs)\n",
    "\n",
    "    # Classification head\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    predictions = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_PATH,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy'\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d22b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670764f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89432dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, generator, data_name='Dataset'):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for i in tqdm(range(len(generator)), desc=f\"Evaluating {data_name}\"):\n",
    "        x, y = generator[i]\n",
    "        batch_pred = model.predict(x, verbose=0)\n",
    "        y_true.extend(np.argmax(y, axis=1))\n",
    "        y_pred.extend(np.argmax(batch_pred, axis=1))\n",
    "\n",
    "    print(f\"\\n{data_name} Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASSES, digits=4))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "    plt.title(f'{data_name} Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating Validation Set...\")\n",
    "evaluate_model(model, val_generator, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)\n",
    "print(f\"Model saved to {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
